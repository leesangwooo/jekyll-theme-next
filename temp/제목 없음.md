##HDFS (Hadoop Distributed File System)
대용량 파일을 분산된 서버에 저장하고, 그 저장된 데이터를 빠르게 처리할 수 있는 블록 구조의 파일 시스템.
\* 블록크기 : 128M(~하둡 2.0)
\* 탐색시간 = seek time(블록찾기) + search time(블록의 데이터를 찾기) 블록크기가 증가하면서 탐색시간이 줄어든다.


#####HDFS의 목표
1. 장애복구
2. 스트리밍 방식의 데이터 접근
3. 대용량 데이터 저장
4. 데이터의 무결성


#####name node(=Master)
- **메타데이터 관리**
: 파일시스템을 유지하기 위한 메타데이터 관리
- **데이터노드 모니터링**
: 데이터노드는 네임노드에게 3초마다 하트비트(heartbeat)를 전송하여 데이터 노드의 실행상태와 용량을 보고.
- **블록관리**
: 장애가 발생한 데이터노드의 블록을 새로운 데이터노드에 복제.
\* 원본 파일 블록을 복제하여(기본 3개) 데이터노드에 저장한다.
\* 네임노드에 장애 발생을 대비하여 2차 name node에 check pointing할 수 있다.(백업)

#####data node(=Slave)
- **클라이언트가 HDFS에 저장하는 파일을 로컬 디스크에 유지.**
: 하나의 파일에 대해 로우데이터(원본)와 메타데이터(체크섬, 파일생성일자 등)를 동시에 저장

##MapReduce 프로세스
1. input data를 한 줄씩 나눈다. (spliting)
2. spliting한 데이터를 key, 갯수를 value로 갖는 map 형태의 list로 변환한다.(map task)
3. map task 결과 key를 기준으로 정렬하고  
Reduce : 변형된 결과를 집계한다.
job tracker
task tracker

`wget http://apache.mirror.cdnetworks.com/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz`

`tar xvfz hadoop-1.2.1.tar.gz`
`ls hadoop-1.2.1`

